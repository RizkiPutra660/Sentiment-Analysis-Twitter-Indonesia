{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter API v2 scraper utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to get API Bearer Token fron Twitter.\n",
    "\n",
    "How to get a Bearer Token:\n",
    " 1. Apply for a Twitter developer account at https://developer.twitter.com/ (create a Project & App).\n",
    " 2. In the Developer Portal go to your App -> Keys and tokens -> Generate Bearer Token (OAuth 2.0 Bearer Token).\n",
    " 3. Make .env file in current directory and put your token inside that file\n",
    "\n",
    " `TWITTER_BEARER_TOKEN=[YOUR BEARER TOKEN]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "from dotenv import load_dotenv\n",
    "import urllib.parse\n",
    "import time\n",
    "import random\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def _get_bearer_token_or_raise(token: Optional[str] = None) -> str:\n",
    "    \"\"\"Return bearer token from argument or environment; raise with guidance if missing.\"\"\"\n",
    "    if token:\n",
    "        return urllib.parse.unquote(token)\n",
    "    token = os.getenv(\"TWITTER_BEARER_TOKEN\")\n",
    "    if token:\n",
    "        # URL-decode the token in case it was pasted URL-encoded\n",
    "        return urllib.parse.unquote(token)\n",
    "    raise RuntimeError(\n",
    "        \"TWITTER_BEARER_TOKEN not found. Generate one at https://developer.twitter.com/ \"\n",
    "        \"and set it with `setx TWITTER_BEARER_TOKEN \\\"<token>\\\"` (PowerShell) or export in your shell. \"\n",
    "        \"If you keep it in a .env file at project root, install `python-dotenv` and this cell will load it automatically.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _sleep_until_reset_or_backoff(resp: requests.Response, attempt: int):\n",
    "    \"\"\"Handle 429 by sleeping until x-rate-limit-reset header or doing exponential backoff.\n",
    "\n",
    "    Args:\n",
    "      resp: the Response object that returned 429\n",
    "      attempt: current retry attempt (0-based)\n",
    "    \"\"\"\n",
    "    reset = resp.headers.get(\"x-rate-limit-reset\")\n",
    "    if reset:\n",
    "        try:\n",
    "            reset_ts = int(reset)\n",
    "            now = int(time.time())\n",
    "            wait = max(reset_ts - now, 0)\n",
    "            # add a small buffer\n",
    "            wait += 5\n",
    "            print(f\"Rate limit reached. Sleeping until reset in {wait} seconds...\")\n",
    "            time.sleep(wait)\n",
    "            return\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Fallback: exponential backoff with jitter\n",
    "    base = 2 ** min(attempt, 6)\n",
    "    jitter = random.uniform(0.5, 1.5)\n",
    "    wait = base * jitter\n",
    "    print(f\"Rate limit (no reset header). Backing off for {wait:.1f} seconds (attempt {attempt})\")\n",
    "    time.sleep(wait)\n",
    "\n",
    "\n",
    "def search_tweets_v2(query: str, count: int = 100, bearer_token: Optional[str] = None, lang: Optional[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Search recent tweets using Twitter API v2 and save results to CSV.\n",
    "\n",
    "    This version handles 429 (Too Many Requests) by examining response headers and\n",
    "    sleeping until the reset time or by using exponential backoff with jitter.\n",
    "\n",
    "    Args:\n",
    "      query: search query string (e.g. \"indonesia -is:retweet\")\n",
    "      count: number of tweets to fetch\n",
    "      bearer_token: optional bearer token string; if omitted reads env var or .env\n",
    "      lang: optional language tag to restrict results (e.g. 'id' for Indonesian)\n",
    "\n",
    "    Returns:\n",
    "      pandas.DataFrame with columns ['Datetime', 'Text']\n",
    "    \"\"\"\n",
    "    token = _get_bearer_token_or_raise(bearer_token)\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "\n",
    "    query_with_lang = f\"{query} lang:{lang}\" if lang else query\n",
    "\n",
    "    params = {\n",
    "        \"query\": query_with_lang,\n",
    "        \"max_results\": 30000,\n",
    "        \"tweet.fields\": \"created_at,text,lang\"\n",
    "    }\n",
    "\n",
    "    tweets = []\n",
    "    next_token = None\n",
    "    attempt = 0\n",
    "\n",
    "    while len(tweets) < count:\n",
    "        if next_token:\n",
    "            params[\"next_token\"] = next_token\n",
    "        try:\n",
    "            resp = requests.get(url, headers=headers, params=params, timeout=30)\n",
    "        except requests.RequestException as e:\n",
    "            # network error; backoff and retry\n",
    "            print(f\"Network error: {e}; backing off...\")\n",
    "            time.sleep(min(60, 2 ** attempt))\n",
    "            attempt += 1\n",
    "            continue\n",
    "\n",
    "        if resp.status_code == 200:\n",
    "            attempt = 0\n",
    "            payload = resp.json()\n",
    "            for t in payload.get(\"data\", []):\n",
    "                # Double-check language if provided (defensive)\n",
    "                if lang and t.get(\"lang\") != lang:\n",
    "                    continue\n",
    "                tweets.append([t.get(\"created_at\"), t.get(\"text\")])\n",
    "                if len(tweets) >= count:\n",
    "                    break\n",
    "            meta = payload.get(\"meta\", {})\n",
    "            next_token = meta.get(\"next_token\")\n",
    "            if not next_token:\n",
    "                break\n",
    "            # small pause between pages to avoid hitting very short-timescale limits\n",
    "            time.sleep(0.5)\n",
    "        elif resp.status_code == 401:\n",
    "            raise RuntimeError(\"Unauthorized: check your TWITTER_BEARER_TOKEN value\")\n",
    "        elif resp.status_code == 429:\n",
    "            # Too Many Requests: check headers and sleep until reset or backoff\n",
    "            _sleep_until_reset_or_backoff(resp, attempt)\n",
    "            attempt += 1\n",
    "            continue\n",
    "        else:\n",
    "            # raise HTTPError for other status codes so user sees the cause\n",
    "            resp.raise_for_status()\n",
    "\n",
    "    df = pd.DataFrame(tweets, columns=[\"Datetime\", \"Text\"])\n",
    "    # Save CSV (filename safe-ish; replace spaces with underscores)\n",
    "    safe_query = query.replace(\" \", \"_\").replace('/', '_')\n",
    "    filename = f\"{safe_query}-{int(count/1000)}k-tweets.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Wrote {len(df)} rows to {filename}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def user_tweets_v2(username: str, count: int = 100, bearer_token: Optional[str] = None, lang: Optional[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch recent tweets from a username using Twitter API v2.\n",
    "\n",
    "    Steps: get user id via users/by/username/:username, then fetch tweets from /users/:id/tweets.\n",
    "    (This function inherits the same 429/backoff approach used above.)\n",
    "    \"\"\"\n",
    "    token = _get_bearer_token_or_raise(bearer_token)\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    # get user id\n",
    "    r = requests.get(f\"https://api.twitter.com/2/users/by/username/{username}\", headers=headers, timeout=30)\n",
    "    if r.status_code != 200:\n",
    "        r.raise_for_status()\n",
    "    user_data = r.json().get(\"data\", {})\n",
    "    user_id = user_data.get(\"id\")\n",
    "    if not user_id:\n",
    "        raise RuntimeError(\"User id not found for username: %s\" % username)\n",
    "\n",
    "    url = f\"https://api.twitter.com/2/users/{user_id}/tweets\"\n",
    "    params = {\"max_results\": 100, \"tweet.fields\": \"created_at,text,lang\"}\n",
    "\n",
    "    tweets = []\n",
    "    next_token = None\n",
    "    attempt = 0\n",
    "    while len(tweets) < count:\n",
    "        if next_token:\n",
    "            params[\"pagination_token\"] = next_token\n",
    "        try:\n",
    "            resp = requests.get(url, headers=headers, params=params, timeout=30)\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Network error: {e}; backing off...\")\n",
    "            time.sleep(min(60, 2 ** attempt))\n",
    "            attempt += 1\n",
    "            continue\n",
    "\n",
    "        if resp.status_code == 200:\n",
    "            attempt = 0\n",
    "            payload = resp.json()\n",
    "            for t in payload.get(\"data\", []):\n",
    "                if lang and t.get(\"lang\") != lang:\n",
    "                    continue\n",
    "                tweets.append([t.get(\"created_at\"), t.get(\"text\")])\n",
    "                if len(tweets) >= count:\n",
    "                    break\n",
    "            meta = payload.get(\"meta\", {})\n",
    "            next_token = meta.get(\"next_token\")\n",
    "            if not next_token:\n",
    "                break\n",
    "            time.sleep(0.5)\n",
    "        elif resp.status_code == 401:\n",
    "            raise RuntimeError(\"Unauthorized: check your TWITTER_BEARER_TOKEN value\")\n",
    "        elif resp.status_code == 429:\n",
    "            _sleep_until_reset_or_backoff(resp, attempt)\n",
    "            attempt += 1\n",
    "            continue\n",
    "        else:\n",
    "            resp.raise_for_status()\n",
    "\n",
    "    df = pd.DataFrame(tweets, columns=[\"Datetime\", \"Text\"])\n",
    "    filename = f\"{username}-{int(count/1000)}k-tweets.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Wrote {len(df)} rows to {filename}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Quick test helper (non-destructive):\n",
    "if __name__ == '__main__':\n",
    "    print(\"Loaded Twitter API v2 utilities. Example usage:\\n  df = search_tweets_v2('indonesia -is:retweet', 10, lang='id')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = search_tweets_v2('indonesia -is:retweet', 30000, lang='id') #input your query, number of tweets, and language here\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
